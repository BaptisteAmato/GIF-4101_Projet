\documentclass{report}
\usepackage[utf8]{inputenc} % force the use of utf8
\usepackage[T1]{fontenc} % font encoding, allows accents
\usepackage{pslatex} %font (ae/pslatex)
\usepackage[papersize={21cm,29.7cm},top= 2.5cm,bottom=2.5cm, inner=2.5cm, outer=2.5cm]{geometry} % page formatting
\usepackage{graphicx} % images management
\usepackage{wrapfig} % floating images
\usepackage{array} % allow arrays
\usepackage{fancyhdr} % headers/footers management (overrides empty, plain and headings)
\usepackage{listings} % code insertion (MUST BE WRITTEN AFTER BABEL)
\usepackage{enumitem} % for /setlist
\usepackage{color,soul} % add some colors and highlight
\usepackage{xcolor} % more colors
\usepackage{float}
\usepackage{bm}
\usepackage{amsmath}
\usepackage[hyphens]{url} % auto break lines in URL
\usepackage[toc,page]{appendix}
\usepackage{titlesec}
\usepackage[hidelinks,  colorlinks  = true, % no borders, colors enabled
                        anchorcolor = blue,
                        linkcolor   = black, % links in table of contents
                        urlcolor    = blue,
                        citecolor   = blue]{hyperref}


\sethlcolor{cyan} % package soul
\newcommand{\file}[1]{\hl{\emph{#1}}} % highlight a file URI

\graphicspath{{Resources/}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LISTINGS %%%%%%%%%%%%%%
\definecolor{comment}{rgb}{0.12, 0.38, 0.18 }
\definecolor{keyword}{rgb}{0.37, 0.08, 0.25}  % #5F1441
\definecolor{string}{rgb}{0.06, 0.10, 0.98} % #101AF9
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand\sectionpostlude{
  \vspace{0.8em}
}
\setlength{\intextsep}{10mm}
\fancypagestyle{plain}{
    %---------------------------------------------------------------------------
    % HEADER
    %---------------------------------------------------------------------------
    \fancyhead[R]{Apprentissage et reconnaissance - Projet}

    %---------------------------------------------------------------------------
    % FOOTER
    %---------------------------------------------------------------------------
    \renewcommand{\footrulewidth}{0.1pt}
    \fancyfoot[C]{Baptiste AMATO, Arnoud VANHUELE \& Alexandre CHAVENON}
    \fancyfoot[LE]{\ifnum\thepage>0 \thepage \fi}
    \fancyfoot[RO]{\ifnum\thepage>0 \thepage \fi}
}

\fancypagestyle{empty}{%
    \renewcommand{\headrulewidth}{0pt} % No sub line
    \fancyhead{} % Empty the header

    \renewcommand{\footrulewidth}{0pt}
    \fancyfoot{}
}

\setlist[itemize,2]{label={$\bullet$}} % use bullets for nested itemize

% First page
\newcommand{\presentation}[1]{\vspace{0.3cm}\large{\textbf{#1}}\vspace{0.3cm}\\}
\newcommand{\presentationLarge}[1]{\vspace{0.3cm}\LARGE{\textbf{#1}}\vspace{0.3cm}\\}

% Overrides chapter (numbered and no-numbered) headings: remove space, display only the title
\makeatletter
  \def\@makechapterhead#1{%
  \vspace*{0\p@}% avant 50
  {\parindent \z@ \raggedright \normalfont
    \interlinepenalty\@M
    \Huge \bfseries \thechapter\quad #1
    \vskip 40\p@
  }}
  \def\@makeschapterhead#1{%
  \vspace*{0\p@}% before 50
  {\parindent \z@ \raggedright
    \normalfont
    \interlinepenalty\@M
    \Huge \bfseries  #1\par\nobreak
    \vskip 40\p@
  }}
\makeatother

\newcommand{\ignore}[1]{} % inline comments

\pagenumbering{arabic}
\pagestyle{plain} % uses fancy

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%-------------------------------------------------------------------------------
% DOCUMENT INFO SECTION
%-------------------------------------------------------------------------------
\title{Apprentissage et reconnaissance - GIF-4101/GIF-7005 - Projet}
\author{Baptiste AMATO, Arnoud VANHUELE \& Alexandre CHAVENON}
\date\today

\begin{document}
\thispagestyle{empty} % only for the current page

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\begin{center}
 \vspace{2.5cm}
 \presentation{Université LAVAL}

 %-------------------------------------------------------------------------------
 % TITLE SECTION
 %-------------------------------------------------------------------------------

 \vspace{4cm}
 \noindent{
  \begin{minipage}{0.9\textwidth}
   \begin{center}
    \HRule \\[0.4cm]
    { \huge \bfseries Apprentissage et reconnaissance \\ GIF-4101/GIF-7005}\\[0.4cm] % Title of the document
    { Projet : Détection automatique de prolongements neuronaux }\\ % Sub-Title of the document
    \HRule \\[1.5cm]
   \end{center}
  \end{minipage}}
 \vspace{4cm}


 %-------------------------------------------------------------------------------
 % AUTHOR SECTION
 %-------------------------------------------------------------------------------

 \begin{minipage}{0.4\textwidth}
  \begin{flushleft} \large
   \emph{Auteurs :}\\
   Baptiste \textsc{Amato} \\
   Arnoud \textsc{Vanhuele} \\
   Alexandre \textsc{Chavenon} \\
  \end{flushleft}
 \end{minipage}

\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}

\section{Présentation du projet}

Le projet est proposé par le centre de recherche CERVO.  Il consiste à reconnaître
des axones et des dendrites sur des images d’une protéine (actine), en étiquetant ces images
n’ayant pas de marqueurs axonaux et dendritiques. Nous disposons d’une banque de
données d’images déjà marquées : il s'agit donc un problème d’apprentissage supervisé.

\section{Jeu de données}

Le jeu de données initial comprend 1024 images au format \textit{.tiff}, ayant
chacune trois canaux : un pour l'actine (la protéine d'intérêt), un pour les axones,
et un pour les dendrites. \\
Ce jeu de données étant relativement petit pour un apprentissage par réseau neuronal,
nous allons utiliser des méthodes d'augmentation comme des symétries et des découpes
de sous-parties des images.

\section{Etat de l'art}

Il s'agit ici de détecter différents objets dans une image (axones et dendrites
à partir d'une image globale d'actine) : c'est un problème de détection particulier,
car il n'est pas possible d'encadrer les objets par des "bounding boxes", utilisées
par exemple pour la détection de visage, de personnes ou de voitures ; on cherche
alors à détecter le contour des objets. Un article de recherche assez récent a
démontré une capacité de détection de contour impressionnante : \textit{Object Contour
 Detection with a Fully Convolutional Encoder-Decoder Network}, par \textbf{Yang
 \textit{et al.}}. Nous nous sommes donc orientés vers un réseau de neurones profond
avec une architecture \textit{Encoder-Decoder} ; cette architecture est aussi
utilisée dans les traductions de textes (séquences en entrée et sortie). Des résultats
probants concernant de la segmentation d'images sont présentés dans l'article
\textit{Iterative Deep Convolutional Encoder-Decoder Network for Medical Image
 Segmentation}, par \textbf{Jung Uk Kim, Hak Gu Kim, et Yong Man Ro}, suivant une
architecture similaire (\textit{Encoder-Decoder}). \\
Les principes de segmentation d'image sont clairement expliqués dans l'article
\textbf{Fully Convolutional Networks for Semantic Segmentation}, par \textbf{Shelhamer
 \textit{et al.}}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Pré-traitements}

\section{Masques}

Une image du jeu de données fournit contient trois canaux, pour l'actine, les axones
et les dendrites. Nous séparons donc le \textit{.tiff} afin d'obtenir trois images,
avec l'actine en vert, les axones en rouge et les dendrites en bleu. Après traitements,
on a des images comme suit :

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{"ex_mask"}
\caption{En haut, un triplet actine-axone-dendrite et en bas les mêmes images une fois le masque appliqué}
\end{figure}

Le pré-traitement commence par une égalisation de l'histogramme des intensités
des images en niveaux de gris, afin de pousser légèrement le contraste et donc faire
ressortir l'information la plus importante. On utilise ensuite deux opérations, une d'érosion
afin de mieux délimiter les contours et une de flou gaussien,
afin de raffiner les continuités qui auront pu être perdues lors de l'érosion. \\
On applique ensuite un \textit{thresholding} sur chaque image,
permettant de supprimer du bruit, soit les pixels de très faible intensité :
on définit un seuil entre 0 et 255 (dans notre cas, 10), et tous les pixels ayant
une valeur inférieure à 10 sont ramenés à 0. On convertit ensuite les images en
RGB et on conserve des valeurs non nulles que pour un canal par image (vert pour
l'actine, rouge pour les axones et bleu pour les dendrites). Toutes les valeurs
sont ramenées entre 0 et 1.

\section{Images d'entrée}

\subsection{Taille}

Les images en entrée sont toutes de dimensions différentes, mais de même résolution.
Il est donc nécessaire de conserver ces résolutions (ayant un sens physique) en
n'effectuant aucun redimensionnement. Le problème est que le réseau de neurones
attend des images de même taille en entrée : nous avons donc découpé chacune des
images en \textit{crops} (petits carrés) de taille 224x224, correspondant à la taille
des images en entrée du réseau \textbf{VGG16}, mentionné plus bas.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{"ex_crop"}
\caption{Exemple de \textit{crop} d'une image d'entrée (actine seule). La faible
résolution n'est pas due à redimensionnement de l'image d'origine mais
seulement de la pauvre qualité d'une capture d'écran}
\end{figure}

\subsection{Contenu}

Notre problème est une détection de contour, mais nous devons inclure la notion
d'\textbf{intensité} dans nos matrices d'entrée (valeur allant de 0 à 255).
Les images sont normalisées entre 0 et 1 ; une matrice d'entraînement sera de
taille 224x224x1 (intensités de l'actine), et le label associé sera une matrice
de taille 224x224x1, selon si l'on souhaite entraîner le réseau sur les axones
ou les dendrites. Nous avions commencé en traitant simultanément les axones et
dendrites (donc en ayant des labels de taille 224x224x2), mais il semblait
que l'un des canaux est souvent sur-appris alors que l'autre était délaissé.
La fonction de perte devait retourner une valeur unique pour la matrice, donc
le réseau n'avait aucun moyen de savoir quel canal devait être corrigé. \\
Nous nous sommes demandés s'il était nécessaire de conserver des valeurs décimales
pour les axones en dendrites, ou bien ne garder que des valeurs binaires comme le
font les autres problèmes de segmentation d'image. Nous avons donc créé deux jeux
de données, l'un binaire, l'autre non, afin de comparer les performances. Il semble
finalement qu'il est préférable de garder des valeurs décimales.

\section{Prédiction d'une nouvelle image}

Là encore, il est nécessaire de procéder par \textit{crops} pour traiter une nouvelle
image. Ainsi, chaque \textit{crop} sera associé à une image de prédiction
et l'image résultante sera reconstituée à partir de ces \textit{crops}. Le réseau
de neurones n'a donc affaires qu'à des images de taille 224x224x1.

\subsection{Augmentation des données}

Nous avons, pour chaque \textit{crop}, ajouté des \textit{flips} (opérations "miroir")
permettant d'avoir quatre nouvelles données en sortie (l'originale, la symmétrie horizontale,
verticale et l'enchaînement des deux). Ces opérations ne sont effectuées que lorsque
le crop est assez "discriminant", c'est-à-dire si la différence entre l'actine
et le masque d'axone ou de dendrite est assez importante.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Réseau de neurones}

Nous utilisons la librairie \textit{Keras} avec un back-end en \textit{TensorFlow}. L'architecture sera celle présentée dans l'article de recherche \textit{Object Contour
Detection with a Fully Convolutional Encoder-Decoder Network}, par \textbf{Yang
\textit{et al.}} : la première partie du réseau est l'encodeur, basé sur l'architecture du réseau \textbf{VGG16}, en s'arrêtant juste avant le \textit{Fully Connected layer}.
Ensuite, le décodeur est celui décrit par l'article, permettant de reconstituer
une image de la taille d'origine avec des opérations de \textit{déconvolution},
qui en \textit{Keras} se font grâce à l'opération \textit{UpSampling} suivie d'une
\textit{same convolution} (convolution ne modifiant pas la taille de l'image d'entrée
grâce à l'ajout de \textit{padding}). \\
L'optimisation est faite avec la méthode \textbf{Adam} utilisant les avantages des
algorithmes \textbf{AdaGrad} et \textbf{RMSProp}  ; celle-ci a fait ses preuves
dans le monde du Deep Learning. Nous utilisons la fonction de perte \textbf{mean
squared error}. \\ \\

\chapter{Tests}

Le jeu de données, après transformations, est très lourd (plusieurs dizaines de Giga Octets).
De plus, chaque image n'est pas fournie telle quelle au réseau de neurones, mais
est découpée en \textit{crops} qui, selon la taille de l'image, peuvent être au nombre
de 30 voire 40 pour une unique image. Ainsi, nos ordinateurs ne pouvaient pas
créer des tableaux \textit{numpy} contenant toutes les données. De plus, lors des
entraînements du réseau, nous avons été confrontés à des \textit{ResourceExhaustedError},
donc nous devions utiliser des tailles de \textit{mini-batches} très petites (4 au plus),
ce qui ne donne pas de bons résultats. \\
Nous avons alors obtenu l'accès à une machine des laboratoires de l'université ayant
un GPU puissant afin d'effectuer des tests sur un grand nombre de données et des
tailles de \textit{mini-batches} raisonnables (32). Il a été nécessaire de créer
une instance \textit{Docker} pour pouvoir empaqueter notre code dans la machine ;
une fois cela fait nous avions accès à distance à notre code et pouvions donc
lancer plusieurs tests sur l'ensemble des données. \\
Chaque exécution de modèle génère deux fichiers, tous deux accompagnés du nom du
modèle en question : l'un conserve la structure du modèle en \textit{.json} et
l'autre sauvegarde les poids appris en \textit{.hdf5}. On peut ainsi "re-créer"
en local le modèle déjà appris et voir ce qu'il donne sur différentes images.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Résultats}

\section{Post-traitement}

Le but est d'obtenir des masques d'axones et dendrites sur une image d'actine.
On ne s'intéresse donc qu'aux valeurs non nulles de l'image d'origine, c'est
pourquoi nous appliquons un masque sur les prédictions afin de n'avoir que du
contenu pouvant être superposé à l'actine d'origine (en effet, dans la plupart
des prédictions, le fond est légèrement coloré, mais cela nous importe peu).

\section{Exemples de prédictions}

% TODO: mettre ici des bons exemples (montrer originales + predictions)

\section{Temps d'entraînement}

Il s'avère que les résultats ci-dessus peuvent être obtenus assez rapidement, après
seulement quelques \textit{epochs}. En fait, le taux d'erreur est de moins de 25\%
à la fin du premier \textit{epoch}, puis stagne autour de 17-18\% après environ cinq
\textit{epochs}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Analyse}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Pistes d'amélioration}

% TODO: dire qu'on n'a pas eu le temps de tester d'autres genres de data augmentation,
% ni beaucoup de modeles à cause du temps d'entrainement long

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Protocole d'utilisation}

La première chose à faire est de créer un fichier \textbf{config.py} et de spécifier
le chemin d'accès vers les images d'origine dans la variable \textit{main\_folder\_path}.
Les images doivent être placées dans un dossier appelé \textit{original\_data} (que
l'on peut modifier dans le fichier \textbf{constants.py}). Il faut ensuite générer
le jeu de données traitées, à l'aide de la fonction \textit{save\_train\_label\_images(number\_of\_images0)}
du fichier \textbf{dataset.py}. Si l'on veut ré-entraîner le modèle, il faut aussi
générer le jeu de données d'entraînement (après augmentation des données), avec
 \textit{save\_dataset(nb\_images, channel)} du même fichier ( \textit{channel} prend l'une
 des valeurs "axons" ou "dendrites"). Un exemple d'entraînement est donné dans le fichier
 \textbf{multi\_testing.py} ; le modèle doit être défini dans le fichier \textbf{models.py}.
 Afin d'afficher une image provenant du jeu de données traitées, il suffit d'appeler
 la fonction \textit{get\_images\_from\_train\_label(X[i], y[i], channel)}, où \textit{X}
 et \textit{y} représentent les jeu de données traitées.



\end{document}
