\documentclass{report}
\usepackage[utf8]{inputenc} % force the use of utf8
\usepackage[T1]{fontenc} % font encoding, allows accents
\usepackage{pslatex} %font (ae/pslatex)
\usepackage[papersize={21cm,29.7cm},top= 2.5cm,bottom=2.5cm, inner=2.5cm, outer=2.5cm]{geometry} % page formatting
\usepackage{graphicx} % images management
\usepackage{wrapfig} % floating images
\usepackage{array} % allow arrays
\usepackage{fancyhdr} % headers/footers management (overrides empty, plain and headings)
\usepackage{listings} % code insertion (MUST BE WRITTEN AFTER BABEL)
\usepackage{enumitem} % for /setlist
\usepackage{color,soul} % add some colors and highlight
\usepackage{xcolor} % more colors
\usepackage{float}
\usepackage{bm}
\usepackage{amsmath}
\usepackage[hyphens]{url} % auto break lines in URL
\usepackage[toc,page]{appendix}
\usepackage{titlesec}
\usepackage[hidelinks,  colorlinks  = true, % no borders, colors enabled
                        anchorcolor = blue,
                        linkcolor   = black, % links in table of contents
                        urlcolor    = blue,
                        citecolor   = blue]{hyperref}


\sethlcolor{cyan} % package soul
\newcommand{\file}[1]{\hl{\emph{#1}}} % highlight a file URI

\graphicspath{{Resources/}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LISTINGS %%%%%%%%%%%%%%
\definecolor{comment}{rgb}{0.12, 0.38, 0.18 }
\definecolor{keyword}{rgb}{0.37, 0.08, 0.25}  % #5F1441
\definecolor{string}{rgb}{0.06, 0.10, 0.98} % #101AF9
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand\sectionpostlude{
  \vspace{0.8em}
}
\setlength{\intextsep}{10mm}
\fancypagestyle{plain}{
    %---------------------------------------------------------------------------
    % HEADER
    %---------------------------------------------------------------------------
    \fancyhead[R]{Apprentissage et reconnaissance - Projet}

    %---------------------------------------------------------------------------
    % FOOTER
    %---------------------------------------------------------------------------
    \renewcommand{\footrulewidth}{0.1pt}
    \fancyfoot[C]{Baptiste AMATO, Alexandre CHAVENON \& Arnoud VANHUELE}
    \fancyfoot[LE]{\ifnum\thepage>0 \thepage \fi}
    \fancyfoot[RO]{\ifnum\thepage>0 \thepage \fi}
}

\fancypagestyle{empty}{%
    \renewcommand{\headrulewidth}{0pt} % No sub line
    \fancyhead{} % Empty the header

    \renewcommand{\footrulewidth}{0pt}
    \fancyfoot{}
}

\setlist[itemize,2]{label={$\bullet$}} % use bullets for nested itemize

% First page
\newcommand{\presentation}[1]{\vspace{0.3cm}\large{\textbf{#1}}\vspace{0.3cm}\\}
\newcommand{\presentationLarge}[1]{\vspace{0.3cm}\LARGE{\textbf{#1}}\vspace{0.3cm}\\}

% Overrides chapter (numbered and no-numbered) headings: remove space, display only the title
\makeatletter
  \def\@makechapterhead#1{%
  \vspace*{0\p@}% avant 50
  {\parindent \z@ \raggedright \normalfont
    \interlinepenalty\@M
    \Huge \bfseries \thechapter\quad #1
    \vskip 40\p@
  }}
  \def\@makeschapterhead#1{%
  \vspace*{0\p@}% before 50
  {\parindent \z@ \raggedright
    \normalfont
    \interlinepenalty\@M
    \Huge \bfseries  #1\par\nobreak
    \vskip 40\p@
  }}
\makeatother

\newcommand{\ignore}[1]{} % inline comments

\pagenumbering{arabic}
\pagestyle{plain} % uses fancy

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%-------------------------------------------------------------------------------
% DOCUMENT INFO SECTION
%-------------------------------------------------------------------------------
\title{Apprentissage et reconnaissance - GIF-4101/GIF-7005 - Projet}
\author{Baptiste AMATO, Alexandre CHAVENON \& Arnoud VANHUELE}
\date\today

\begin{document}
\thispagestyle{empty} % only for the current page

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\begin{center}
 \vspace{2.5cm}
 \presentation{Université LAVAL}

 %-------------------------------------------------------------------------------
 % TITLE SECTION
 %-------------------------------------------------------------------------------

 \vspace{4cm}
 \noindent{
  \begin{minipage}{0.9\textwidth}
   \begin{center}
    \HRule \\[0.4cm]
    { \huge \bfseries Apprentissage et reconnaissance \\ GIF-4101/GIF-7005}\\[0.4cm] % Title of the document
    { Projet : Détection automatique de prolongements neuronaux }\\ % Sub-Title of the document
    \HRule \\[1.5cm]
   \end{center}
  \end{minipage}}
 \vspace{4cm}


 %-------------------------------------------------------------------------------
 % AUTHOR SECTION
 %-------------------------------------------------------------------------------

 \begin{minipage}{0.4\textwidth}
  \begin{flushleft} \large
   \emph{Auteurs :}\\
   Baptiste \textsc{Amato} \\
   Alexandre \textsc{Chavenon} \\
   Arnoud \textsc{Vanhuele} \\
  \end{flushleft}
 \end{minipage}

\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}

\section{Présentation du projet}

Le projet est proposé par le centre de recherche CERVO.  Il consiste à reconnaître
des axones et des dendrites sur des images d’une protéine (actine), en étiquetant ces images
n’ayant pas de marqueurs axonaux et dendritiques. Nous disposons d’une banque de
données d’images déjà marquées : il s'agit donc un problème d’apprentissage supervisé.

\section{Jeu de données}

Le jeu de données initial comprend 1024 images au format \textit{.tiff}, ayant
chacune 3 canaux : un pour l'actine (la protéine d'intérêt), un pour les axones,
et un pour les dendrites. \\
Ce jeu de données étant relativement petit pour un apprentissage par réseau neuronal,
nous allons utiliser des méthodes d'augmentation comme les symétries, rotations, ou
encore découpes de sous-parties des images.

\section{Etat de l'art}

Il s'agit ici de détecter différents objets dans une image (axones et dendrites
à partir d'une image globale d'actine) : c'est un problème de détection particulier,
car il n'est pas possible d'encadrer les objets par des "bounding boxes", utilisées
par exemple pour la détection de visage, de personnes ou de voitures ; on cherche
alors à détecter le contour des objets. Un article de recherche assez récent a
démontré une capacité de détection de contour impressionnante : \textit{Object Contour
 Detection with a Fully Convolutional Encoder-Decoder Network}, par \textbf{Yang
 \textit{et al.}}. Nous pensons donc nous orienter vers un réseau de neurones profond
avec une architecture \textit{Encoder-Decoder} ; cette architecture est aussi
utilisé dans les traductions de textes (séquences en entrée et sortie). Des résultats
probants concernant de la segmentation d'images sont présentés dans l'article
\textit{Iterative Deep Convolutional Encoder-Decoder Network for Medical Image
 Segmentation}, par \textbf{Jung Uk Kim, Hak Gu Kim, et Yong Man Ro}, suivant une
architecture similaire (\textit{Encoder-Decoder}). \\
Les principes de segmentation d'image sont clairement expliqués dans l'article
\textbf{Fully Convolutional Networks for Semantic Segmentation}, par \textbf{Shelhamer
 \textit{et al.}}. \\
Concernant l’augmentation de notre jeu de données, nous aurons une approche
classique par traitement d’image traditionnel et dans un second temps, nous
explorerons la possibilité d'utiliser un Generative Adversarial Network pour l’augmentation
des données, comme précisé dans l'article\textit{Biomedical Data Augmentation Using
Generative Adversarial Neural Networks. Artificial Neural Networks and Machine
Learning} par \textbf{Calimeri, F.
 \textit{et al.}}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Pré-traitements}

\section{Masques}

Une image du jeu de données fournit contient trois canaux, pour l'actine, les axones
et les dendrites. Nous séparons donc le \textit{.tiff} afin d'obtenir trois images,
avec l'actine en vert, les axones en rougeet les dendrites en bleu. Après traitements,
on a des images comme suit :

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{"ex_mask"}
\caption{En haut, un triplet actine-axone-dendrite, et en bas les mêmes images une fois le masque appliqué}
\end{figure}

Le pré-traitement commence par une égalisation de l'histogramme des intensités
des images en niveaux de gris, afin de pousser légèrement le contraste, et donc faire
ressortir l'information la plus importante. On utilise ensuite deux opérations, une d'érosion
afin de mieux délimiter les contours, et une de flou gaussien,
afin de raffiner les continuités qui auront pu être perdues lors de l'érosion. \\
On applique ensuite un \textit{thresholding} sur chaque image,
permettant de supprimer du bruit, soit les pixels de très faible intensité :
on définit un seuil entre 0 et 255 (dans notre cas, 10), et tous les pixels ayant
une valeur inférieure à 10 sont ramenés à 0. On convertit ensuite les images en
RGB, et on ne conserve des valeurs non nulles que pour un canal par image (vert pour
l'actine, rouge pour les axones et bleu pour les dendrites). Toutes les valeurs
sont ramenées entre 0 et 1.

\section{Images d'entrée}

\subsection{Taille}

Les images en entrée sont toutes de dimensions différentes, mais de même résolution.
Il est donc nécessaire de conserver ces résolutions (ayant un sens physique) en
n'effectuant aucun redimmensionnement. Le problème est que le réseau de neurones
attend des images de même taille en entrée : nous avons donc découpé chacune des
images en \textit{crops} (petits carrés) de taille 224x224, correspondant à la taille
des images en entrée du réseau \textbf{VGG16}, mentionné plus bas.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{"ex_crop"}
\caption{Exemple de \textit{crop} d'une image d'entrée (actine seule). La faible
résolution n'est dûe à aucun redimmensionnement de l'image d'origine, il s'agit
seulement de la pauvre qualité d'une capture d'écran}
\end{figure}

\subsection{Contenu}

Notre problème est une détection de contour, mais nous devons inclure la notion
d'\textbf{intensité} dans nos matrices d'entrée (valeur allant de 0 à 255).
Les images sont normalisées entre 0 et 1 ; une matrice d'entraînement sera de
taille 224x224x1 (intensités de l'actine), et le label associé sera une matrice
de taille 224x224x1, selon si l'on souhaite entraîner le réseau sur les axones
ou les dendrites. Nous avions commencé en traitant simultanément les axones et
dendrites (donc en ayant des labels de taille 224x224x2), mais il semblait
que l'un des channels est souvent sur-appris alors que l'autre était délaissé.
La fonction de perte devait retourner une valeur unique pour la matrice, donc
le réseau n'avait aucun moyen de savoir quel channel devait être corrigé. \\
Nous nous sommes demandés s'il était nécessaire de conserver des valeurs décimales
pour les axones en dendrites, ou bien ne garder que des valeurs binaires comme le
font les autres problèmes de segmentation d'image. Nous avons donc créé deux jeux
de données, l'un binaire, l'autre non, afin de comparer les performances.

\section{Prédiction d'une nouvelle image}

Là encore, il est nécessaire de procéder par \textit{crops} pour traiter une nouvelle
image. Ainsi, chaque \textit{crop} sera associé à une image de prédiction,
et l'image résultante sera reconstituée à partir de ces \textit{crops}. Le réseau
de neurones n'a donc affaires qu'à des images de taille 224x2242z.

\subsection{Augmentation des données}

Nous avons, pour chaque \textit{crop}, ajouté des \textit{flips} (opérations "miroir")
permettant d'avoir en sortie 4 nouvelles données (l'originale, la symmétrie horizontale,
verticale et l'enchaînement des deux). Ces opérations ne sont effectuées que lorsque
l'image contient de l'information intéressante, c'est-à-dire si elle n'est pas trop
noire ni trop colorée (en effet, dans ces cas, les opérations de symmétrie n'auraient
que peu d'intérêt).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Réseau de neurones}

Nous utilisons la librairie \textit{Keras} avec un back-end en \textit{TensorFlow}.
L'architecture sera celle présentée dans l'article de recherche \textit{Object Contour
Detection with a Fully Convolutional Encoder-Decoder Network}, par \textbf{Yang
\textit{et al.}} : la première parte du réseau est l'encodeur, basé sur l'architecture
du réseau \textbf{VGG16}, en s'arrêtant juste avant le \textit{Fully Connected layer}.
Ensuite, le décodeur est celui décrit par l'article, permettant de reconstituer
une image de la taille d'origine avec des opérations de \textit{déconvolution},
qui en \textit{Keras} se font grâce à l'opération \textit{UpSampling} suivie d'une
\textit{same convolution} (convolution ne modifiant pas la taille de l'image d'entrée
grâce à l'ajout de \textit{padding}). \\
L'optimisation est faite avec la méthode \textbf{Adam} utilisant les avantages des
algorithmes \textbf{AdaGrad} et \textbf{RMSProp}  ; celle-ci a fait ses preuves
dans le monde du Deep Learning.
+ TODO: loss function

\chapter{Tests}

Le jeu de données, après transformations, est très lourd (plusieurs dizaines de Giga Octets).
De plus, chaque image n'est pas fournie telle quelle au réseau de neurones, mais
est découpée en \textit{crops} qui, selon la taille de l'image, peuvent être au nombre
de 30 voire 40 pour une unique image. Ainsi, nos ordinateurs ne pouvaient pas
créer des tableaux \textit{numpy} contenant toutes les données. De plus, lors des
entraînements du réseau, nous avons été confrontés à des \textit{ResourceExhaustedError},
donc nous devions utiliser des tailles de \textit{mini-batches} très petites (4 au plus),
ce qui ne donne pas de bons résultats. \\
Nous avons alors obtenu l'accès à une machine des laboratoires de l'université ayant
un GPU puissant afin d'effectuer des tests sur un grand nombre de données et des
tailles de \textit{mini-batches} raisonnables (32). Il a été nécessaire de créer
une instance \textit{Docker} pour pouvoir empaqueter notre code dans la machine ;
une fois cela fait nous avions accès à distance à notre code et pouvions donc
lancer plusieurs tests sur l'ensemble des données. \\
Chaque exécution de modèle génère deux fichiers, tous deux accompagnés du nom du
modèle en question : l'un conserve la structure du modèle en \textit{.json} et
l'autre sauvegarde les poids appris en \textit{.hdf5}. On peut ainsi "re-créer"
en local le modèle déjà appris et voir ce qu'il donne sur différentes images.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Résultats}

\section{Post-traitement}

Le but est d'obtenir des masques d'axones et dendrites sur une image d'actine.
On ne s'intéresse donc qu'aux valeurs non nulles de l'image d'origine, c'est
pourquoi nous appliquons un masque sur les prédictions afin de n'avoir que du
contenu pouvant être superposé àl'actine d'origine (en effet, dans la plupart
des prédictions, le fond est légèrement coloré, mais cela nous importe peu).

\section{Premiers résultats}

Nos premiers résultats ont montré que notre réseau avait du mal à distinguer
les axones et dendrites de l'actine. En effet, on voit ci-dessous que les deux labels
retracent en grande partie l'image de l'actine, bien que les dendrites soient assez
bien détourées. Afin de supprimer les faibles intensités, correspondant aux valeurs
"peu sûres", nous appliquons un \textit{threshold} en post-traitement.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{"truth"}
\caption{Images originales, avec l'image fusionnée, les axones et les dendrites}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{"result"}
\caption{Images prédites, avec l'image fusionnée, les axones et les dendrites}
\end{figure}

Les résultats ci-dessus ont été obtenus avec le modèle issu de l'article de
\textit{Yang et al.}, entraînés sur 500 images d'origine. On obtient un erreur
très élevée d'environ 45\%. \\ \\
En modifiant la fonction de perte, on obtient de meilleurs résultats, jusqu'à
sur-apprendre :

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{"result_overfit_truth"}
\caption{Vérité : actine et axones}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.8]{"result_overfit"}
\caption{Prédiction sur les axones}
\end{figure}

\section{Cas bien prédits}

Nous avons beaucoup plus de mal à ne pas sur-apprendre les axones, étant donné
que le masque de ceux-ci est souvent très proche de l'actine. On obtient de bons
résultats avec les dendrites, comme suit :

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{"good_result_truth"}
\caption{Vérité : actine et dendrites}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.8]{"good_result"}
\caption{Prédiction sur les dendrites}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{"2_truth"}
\caption{Vérité : actine et dendrites}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.8]{"2_result"}
\caption{Prédiction sur les dendrites}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{"91_truth"}
\caption{Vérité : actine et dendrites}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.8]{"91_result"}
\caption{Prédiction sur les dendrites}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{"397_truth"}
\caption{Vérité : actine et dendrites}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.8]{"397_result"}
\caption{Prédiction sur les dendrites}
\end{figure}

\section{Labels binaires ou non ? Séparation des labels ?}

Il s'avère que les prédictions sont semblables, que nous gardions des intensités
décimales entre 0 et 1 ou bien des valeurs binaires pour les masques des axones
et des dendrites. \\
En revanche, il est clair que le réseau donne de bien meilleurs résultats lorsque
les axones et dendrites sont prédits séparemment.

\section{Temps d'entraînement}

Il s'avère que les résultats ci-dessus peuvent être obtenus assez rapidement, après
seulement quelques \textit{epochs}. En fait, le taux d'erreur est de moins de 25\%
à la fin du premier \textit{epoch}, puis stagne autour de 17-18\% après environ 5
\textit{epochs}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Analyse}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Contraintes}

Les images fournies étaient en moyenne de haute résolution. Ainsi, les données
avant augmentation pesaient déjà assez lourd, mais après augmentation nous
avions un jeu de données d'environ 55 gigas. De plus, nous devions utiliser un
ordinateur à distance afin d'avoir un GPU puissant, ce qui rendait les transferts
de données compliqués (sans parler du fait que l'espace mémoire de l'ordinateur
à distance était en grande partie utilisé). Cela a donc grandement ralenti le
processus, étant donné que la sauvegarde du jeu de données entier après augmentation
prenait un jour entier. Nous n'avons donc pas pu tester différentes augmentations
sur l'ensemble des images d'origine. \\
L'entraînement était aussi particulièrement long ; nous disposions de plus de
110 000 matrices à traiter (après augmentation). Un entraînement sur 70\% des
données (en enlevant une partie pour les tests), pendant 30 epochs prenait une
dizaine d'heures.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Pistes d'amélioration}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Protocole d'utilisation}

TODO: save train / label + save dataset + train + test



\end{document}
