{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from dataset import *\n",
    "from multi_testing import *\n",
    "from tests import *\n",
    "from image_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actin, predicted_dendrite = test_image(0, \"model_yang\", \"axons\", binary_masks=False, thresh_results=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "binary_masks = True\n",
    "x = np.load(get_folder_images_saving_train_x(binary_masks) + \"/\" + str(i) + \".npy\")\n",
    "y = np.load(get_folder_images_saving_train_y(binary_masks) + \"/\" + str(i) + \".npy\")\n",
    "actin, axon = get_images_from_train_label(x, y, 'dendrites')\n",
    "\n",
    "plt.imshow(axon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "AUGMENTING THE DATA\n",
      "0\n",
      "SAVING THE HDF5 FILE\n",
      "Length: 185\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "save_train_label_images(5, binary_masks=False)\n",
    "save_dataset(5, binary_masks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## TESTING MODEL model_yang #########\n",
      "######## LOADING THE MODEL ###########\n",
      "number of training examples = 7\n",
      "number of test examples = 3\n",
      "X_train shape: (7, 224, 224, 1)\n",
      "Y_train shape: (7, 224, 224, 1)\n",
      "X_test shape: (3, 224, 224, 1)\n",
      "Y_test shape: (3, 224, 224, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maewanto/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## RUNNING THE MODEL ###########\n",
      "Train on 4 samples, validate on 3 samples\n",
      "Epoch 1/11\n",
      "######## ResourceExhaustedError ###########\n",
      "######## RUNNING THE MODEL with batch_size = 2.0 ###########\n",
      "Train on 4 samples, validate on 3 samples\n",
      "Epoch 1/11\n",
      "2/4 [==============>...............] - ETA: 2s - loss: 0.2638 - acc: 0.3875Epoch 00001: val_loss improved from inf to 0.28080, saving model to /media/maewanto/B498-74ED/Data_projet_apprentissage/models_weights/axons/non_binary/model_yang_weights.hdf5\n",
      "4/4 [==============================] - 9s 2s/step - loss: 0.2221 - acc: 0.5074 - val_loss: 0.2808 - val_acc: 0.0555\n",
      "Epoch 2/11\n",
      "2/4 [==============>...............] - ETA: 0s - loss: 0.1626 - acc: 0.5660Epoch 00002: val_loss did not improve\n",
      "4/4 [==============================] - 1s 372ms/step - loss: 0.1967 - acc: 0.6694 - val_loss: 0.8336 - val_acc: 0.0014\n",
      "Epoch 3/11\n",
      "2/4 [==============>...............] - ETA: 0s - loss: 0.1606 - acc: 0.5977Epoch 00003: val_loss did not improve\n",
      "4/4 [==============================] - 1s 370ms/step - loss: 0.1875 - acc: 0.7387 - val_loss: 0.8653 - val_acc: 0.0012\n",
      "######## LOADING THE BEST WEIGHTS ###########\n",
      "######## EVALUATING THE MODEL ###########\n",
      "3/3 [==============================] - 1s 410ms/step\n",
      "\n",
      "Loss = 0.274122476578\n",
      "Test Accuracy = 0.058095511049\n"
     ]
    }
   ],
   "source": [
    "models_to_test = [\n",
    "    {\n",
    "        'name': 'model_yang',\n",
    "        'nb_examples': 10,\n",
    "        'validation_split': 0.3,\n",
    "        'epochs': 1,\n",
    "        'batch_size': 4,\n",
    "        'use_saved_weights': False,\n",
    "        'channel': 'axons',\n",
    "        'binary_masks': False,\n",
    "        'train_test_splitting': True\n",
    "    }\n",
    "]\n",
    "run_multi_tests(models_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_files_path_generator():\n",
    "    \"\"\"\n",
    "    Generator of original tif files' path\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for subdir, dirs, files in os.walk(original_data):\n",
    "        for file in files:\n",
    "            filename, file_extension = os.path.splitext(file)\n",
    "            if file_extension == \".tif\":\n",
    "                yield os.path.join(subdir, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1041\n",
      "11/1041\n",
      "21/1041\n",
      "31/1041\n",
      "41/1041\n",
      "51/1041\n",
      "61/1041\n",
      "71/1041\n",
      "81/1041\n",
      "91/1041\n",
      "101/1041\n",
      "111/1041\n",
      "121/1041\n",
      "131/1041\n",
      "141/1041\n",
      "151/1041\n",
      "161/1041\n",
      "171/1041\n",
      "181/1041\n",
      "191/1041\n",
      "201/1041\n",
      "211/1041\n",
      "221/1041\n",
      "231/1041\n",
      "241/1041\n",
      "251/1041\n",
      "261/1041\n",
      "271/1041\n",
      "281/1041\n",
      "291/1041\n",
      "301/1041\n",
      "311/1041\n",
      "321/1041\n",
      "331/1041\n",
      "341/1041\n",
      "351/1041\n",
      "361/1041\n",
      "371/1041\n",
      "381/1041\n",
      "391/1041\n",
      "401/1041\n",
      "411/1041\n",
      "421/1041\n",
      "431/1041\n",
      "441/1041\n",
      "451/1041\n",
      "461/1041\n",
      "471/1041\n",
      "481/1041\n",
      "491/1041\n",
      "501/1041\n",
      "511/1041\n",
      "521/1041\n",
      "531/1041\n",
      "541/1041\n",
      "551/1041\n",
      "561/1041\n",
      "571/1041\n",
      "581/1041\n",
      "591/1041\n",
      "601/1041\n",
      "611/1041\n",
      "621/1041\n",
      "631/1041\n",
      "641/1041\n",
      "651/1041\n",
      "661/1041\n",
      "671/1041\n",
      "681/1041\n",
      "691/1041\n",
      "701/1041\n",
      "711/1041\n",
      "721/1041\n",
      "731/1041\n",
      "741/1041\n",
      "751/1041\n",
      "761/1041\n",
      "771/1041\n",
      "781/1041\n",
      "791/1041\n",
      "801/1041\n",
      "811/1041\n",
      "821/1041\n",
      "831/1041\n",
      "841/1041\n",
      "851/1041\n",
      "861/1041\n",
      "871/1041\n",
      "881/1041\n",
      "891/1041\n",
      "901/1041\n",
      "911/1041\n",
      "921/1041\n",
      "931/1041\n",
      "941/1041\n",
      "951/1041\n",
      "961/1041\n",
      "971/1041\n",
      "981/1041\n",
      "991/1041\n",
      "1001/1041\n",
      "1011/1041\n",
      "462\n",
      "/media/maewanto/B498-74ED/Data_projet_apprentissage/original_data/2017-10-19 EXP204 MDL DIV8/05_Glu-Gly_100uM_MDL_SMI31-STAR580_MAP2-STAR488_PhSTAR635_5.msr_STED640_Conf561_Conf488_merged.tif\n",
      "456\n",
      "/media/maewanto/B498-74ED/Data_projet_apprentissage/original_data/2017-10-19 EXP204 MDL DIV8/05_Glu-Gly_100uM_MDL_SMI31-STAR580_MAP2-STAR488_PhSTAR635_10.msr_STED640_Conf561_Conf488_merged.tif\n"
     ]
    }
   ],
   "source": [
    "N = 1041\n",
    "count = 0\n",
    "min_rows = np.inf\n",
    "min_cols = np.inf\n",
    "min_rows_img = \"\"\n",
    "min_cols_img = \"\"\n",
    "i = 0\n",
    "for file_path in get_files_path_generator():\n",
    "    if i % 10 == 0:\n",
    "        print(str(i + 1) + \"/\" + str(N))\n",
    "    image = tifffile.imread(file_path)\n",
    "    # Remove number of channels from shape\n",
    "    shape = image.shape[1:]\n",
    "    if min_rows > shape[0]:\n",
    "        min_rows = shape[0]\n",
    "        min_rows_img = file_path\n",
    "    if min_cols > shape[1]:\n",
    "        min_cols = shape[1]\n",
    "        min_cols_img = file_path\n",
    "#     if shape[0] < 448 or shape[1] < 448:\n",
    "#         count += 1\n",
    "#         print(file_path)\n",
    "#         os.rename(file_path, file_path.replace(\"original_data\", \"too_small_images\"))\n",
    "    i += 1\n",
    "# print(count)\n",
    "print(min_rows)\n",
    "print(min_rows_img)\n",
    "print(min_cols)\n",
    "print(min_cols_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
