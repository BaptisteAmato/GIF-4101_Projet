{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from dataset import *\n",
    "from multi_testing import *\n",
    "from tests import *\n",
    "from image_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actin, predicted_dendrite = test_image(643, \"model_yang_deeper\", \"dendrites\", binary_masks=False, thresh_results=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Good examples dendrites: 2, 91, 397"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save_train_label_images(1041, binary_masks=False)\n",
    "save_dataset(5, binary_masks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = [\n",
    "    {\n",
    "        'name': 'model_yang',\n",
    "        'nb_examples': 5,\n",
    "        'validation_split': 0.3,\n",
    "        'epochs': 1,\n",
    "        'batch_size': 4,\n",
    "        'use_saved_weights': False,\n",
    "        'channel': 'axons',\n",
    "        'binary_masks': False,\n",
    "        'train_test_splitting': False\n",
    "    }\n",
    "]\n",
    "run_multi_tests(models_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_files_path_generator():\n",
    "    \"\"\"\n",
    "    Generator of original tif files' path\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for subdir, dirs, files in os.walk(original_data):\n",
    "        for file in files:\n",
    "            filename, file_extension = os.path.splitext(file)\n",
    "            if file_extension == \".tif\":\n",
    "                yield os.path.join(subdir, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = 1041\n",
    "count = 0\n",
    "min_rows = np.inf\n",
    "min_cols = np.inf\n",
    "min_rows_img = \"\"\n",
    "min_cols_img = \"\"\n",
    "i = 0\n",
    "for file_path in get_files_path_generator():\n",
    "    if i % 10 == 0:\n",
    "        print(str(i + 1) + \"/\" + str(N))\n",
    "    image = tifffile.imread(file_path)\n",
    "    # Remove number of channels from shape\n",
    "    shape = image.shape[1:]\n",
    "    if min_rows > shape[0]:\n",
    "        min_rows = shape[0]\n",
    "        min_rows_img = file_path\n",
    "    if min_cols > shape[1]:\n",
    "        min_cols = shape[1]\n",
    "        min_cols_img = file_path\n",
    "#     if shape[0] < 448 or shape[1] < 448:\n",
    "#         count += 1\n",
    "#         print(file_path)\n",
    "#         os.rename(file_path, file_path.replace(\"original_data\", \"too_small_images\"))\n",
    "    i += 1\n",
    "# print(count)\n",
    "print(min_rows)\n",
    "print(min_rows_img)\n",
    "print(min_cols)\n",
    "print(min_cols_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUGMENTING THE DATA\n",
      "0: Length = 0\n",
      "10: Length = 528\n",
      "20: Length = 1527\n",
      "30: Length = 2417\n",
      "40: Length = 3391\n",
      "50: Length = 4217\n",
      "60: Length = 4952\n",
      "70: Length = 5779\n",
      "80: Length = 6524\n",
      "90: Length = 7099\n",
      "100: Length = 7690\n",
      "110: Length = 8407\n",
      "120: Length = 9146\n",
      "130: Length = 9594\n",
      "140: Length = 10448\n",
      "150: Length = 11289\n",
      "160: Length = 12015\n",
      "170: Length = 12435\n",
      "180: Length = 12885\n",
      "190: Length = 13339\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-acec87432ebc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\": Length = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_folder_images_saving_train_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_masks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_folder_images_saving_train_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_masks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mcrops_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrops_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_crops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrops_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 419\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_images = 500\n",
    "binary_masks = False\n",
    "min_ones_ratio=0.2\n",
    "max_ones_ratio=0.8\n",
    "lim_min=0.1\n",
    "lim_max=0.9\n",
    "\n",
    "print(\"AUGMENTING THE DATA\")\n",
    "min_ones = crop_size * crop_size * min_ones_ratio\n",
    "max_ones = crop_size * crop_size * max_ones_ratio\n",
    "total = 0\n",
    "train_set_x_orig = []\n",
    "train_set_y_axon_orig = []\n",
    "train_set_y_dendrite_orig = []\n",
    "for i in range(0, nb_images):\n",
    "    if i % 10 == 0:\n",
    "        print(str(i) + \": Length = \" + str(total))\n",
    "    x = np.load(get_folder_images_saving_train_x(binary_masks) + \"/\" + str(i) + \".npy\")\n",
    "    y = np.load(get_folder_images_saving_train_y(binary_masks) + \"/\" + str(i) + \".npy\")\n",
    "    crops_x, crops_y = get_all_crops(x, y)\n",
    "    length = crops_x.shape[0]\n",
    "    for j in range(0, length):\n",
    "        # We do not want to keep too many black crops, so we make sure there is some data in both train and label\n",
    "        # matrices before taking the flips.\n",
    "        crop_x_j = crops_x[j]\n",
    "        crop_y_j = crops_y[j]\n",
    "        positive_axon = np.where(crop_y_j[:, :, 0] > 0)\n",
    "        actin_minus_axon = crop_x_j.copy()\n",
    "        actin_minus_axon[positive_axon] = 0\n",
    "        positive_dendrite = np.where(crop_y_j[:, :, 1] > 0)\n",
    "        actin_minus_dendrite = crop_x_j.copy()\n",
    "        actin_minus_dendrite[positive_dendrite] = 0\n",
    "        if np.sum(actin_minus_axon > 0) > min_ones and np.sum(actin_minus_dendrite > 0) > min_ones:\n",
    "            flips_x, flips_y = get_flips_images(crops_x[j], crops_y[j])\n",
    "            for k in range(0, 4):\n",
    "                total += 1\n",
    "#                 train_set_x_orig.append(flips_x[k])\n",
    "#                 train_set_y_axon_orig.append(flips_y[k, :, :, 0])\n",
    "#                 train_set_y_dendrite_orig.append(flips_y[k, :, :, 1])\n",
    "        else:\n",
    "            total += 1\n",
    "#             train_set_x_orig.append(crops_x[j])\n",
    "#             train_set_y_axon_orig.append(crops_y[j, :, :, 0])\n",
    "#             train_set_y_dendrite_orig.append(crops_y[j, :, :, 1])\n",
    "            \n",
    "print(\"Length: \" + str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
