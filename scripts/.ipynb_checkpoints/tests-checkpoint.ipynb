{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from dataset import *\n",
    "from multi_testing import *\n",
    "from tests import *\n",
    "from image_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actin, predicted_dendrite = test_image(643, \"model_yang_deeper\", \"dendrites\", binary_masks=False, thresh_results=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Good examples dendrites: 2, 91, 397"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save_train_label_images(1041, binary_masks=False)\n",
    "save_dataset(5, binary_masks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = [\n",
    "    {\n",
    "        'name': 'model_yang',\n",
    "        'nb_examples': 5,\n",
    "        'validation_split': 0.3,\n",
    "        'epochs': 1,\n",
    "        'batch_size': 4,\n",
    "        'use_saved_weights': False,\n",
    "        'channel': 'axons',\n",
    "        'binary_masks': False,\n",
    "        'train_test_splitting': False\n",
    "    }\n",
    "]\n",
    "run_multi_tests(models_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_files_path_generator():\n",
    "    \"\"\"\n",
    "    Generator of original tif files' path\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for subdir, dirs, files in os.walk(original_data):\n",
    "        for file in files:\n",
    "            filename, file_extension = os.path.splitext(file)\n",
    "            if file_extension == \".tif\":\n",
    "                yield os.path.join(subdir, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = 1041\n",
    "count = 0\n",
    "min_rows = np.inf\n",
    "min_cols = np.inf\n",
    "min_rows_img = \"\"\n",
    "min_cols_img = \"\"\n",
    "i = 0\n",
    "for file_path in get_files_path_generator():\n",
    "    if i % 10 == 0:\n",
    "        print(str(i + 1) + \"/\" + str(N))\n",
    "    image = tifffile.imread(file_path)\n",
    "    # Remove number of channels from shape\n",
    "    shape = image.shape[1:]\n",
    "    if min_rows > shape[0]:\n",
    "        min_rows = shape[0]\n",
    "        min_rows_img = file_path\n",
    "    if min_cols > shape[1]:\n",
    "        min_cols = shape[1]\n",
    "        min_cols_img = file_path\n",
    "#     if shape[0] < 448 or shape[1] < 448:\n",
    "#         count += 1\n",
    "#         print(file_path)\n",
    "#         os.rename(file_path, file_path.replace(\"original_data\", \"too_small_images\"))\n",
    "    i += 1\n",
    "# print(count)\n",
    "print(min_rows)\n",
    "print(min_rows_img)\n",
    "print(min_cols)\n",
    "print(min_cols_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUGMENTING THE DATA\n",
      "0: Length = 0\n"
     ]
    }
   ],
   "source": [
    "nb_images = 10\n",
    "binary_masks = False\n",
    "min_ones_ratio=0.2\n",
    "max_ones_ratio=0.8\n",
    "lim_min=0.1\n",
    "lim_max=0.9\n",
    "\n",
    "print(\"AUGMENTING THE DATA\")\n",
    "min_ones = crop_size * crop_size * min_ones_ratio\n",
    "max_ones = crop_size * crop_size * max_ones_ratio\n",
    "total = 0\n",
    "train_set_x_orig = []\n",
    "train_set_y_axon_orig = []\n",
    "train_set_y_dendrite_orig = []\n",
    "for i in range(0, nb_images):\n",
    "    if i % 10 == 0:\n",
    "        print(str(i) + \": Length = \" + str(total))\n",
    "    x = np.load(get_folder_images_saving_train_x(binary_masks) + \"/\" + str(i) + \".npy\")\n",
    "    y = np.load(get_folder_images_saving_train_y(binary_masks) + \"/\" + str(i) + \".npy\")\n",
    "    crops_x, crops_y = get_all_crops(x, y)\n",
    "    length = crops_x.shape[0]\n",
    "    for j in range(0, length):\n",
    "        # We do not want to keep too many black crops, so we make sure there is some data in both train and label\n",
    "        # matrices before taking the flips.\n",
    "        crop_x_j = crops_x[j]\n",
    "        crop_y_j = crops_y[j]\n",
    "        positive_axon = np.where(crop_y_j[:, :, 0] > 0)\n",
    "        actin_minus_axon = crop_x_j.copy()\n",
    "        actin_minus_axon[positive_axon] = 0\n",
    "        positive_dendrite = np.where(crop_y_j[:, :, 1] > 0)\n",
    "        actin_minus_dendrite = crop_x_j.copy()\n",
    "        actin_minus_dendrite[positive_dendrite] = 0\n",
    "        if np.sum(actin_minus_axon > 0) > min_ones and np.sum(actin_minus_dendrite > 0) > min_ones:\n",
    "            flips_x, flips_y = get_flips_images(crops_x[j], crops_y[j])\n",
    "            for k in range(0, 4):\n",
    "                total += 1\n",
    "                train_set_x_orig.append(flips_x[k])\n",
    "                train_set_y_axon_orig.append(flips_y[k, :, :, 0])\n",
    "                train_set_y_dendrite_orig.append(flips_y[k, :, :, 1])\n",
    "        else:\n",
    "            total += 1\n",
    "            train_set_x_orig.append(crops_x[j])\n",
    "            train_set_y_axon_orig.append(crops_y[j, :, :, 0])\n",
    "            train_set_y_dendrite_orig.append(crops_y[j, :, :, 1])\n",
    "            \n",
    "print(\"Length: \" + str(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_images = 200\n",
    "binary_masks = False\n",
    "min_ones_ratio=0.2\n",
    "max_ones_ratio=0.8\n",
    "lim_min=0.1\n",
    "lim_max=0.9\n",
    "\n",
    "print(\"AUGMENTING THE DATA\")\n",
    "min_ones = crop_size * crop_size * min_ones_ratio\n",
    "max_ones = crop_size * crop_size * max_ones_ratio\n",
    "total = 0\n",
    "for i in range(0, nb_images):\n",
    "    if i % 10 == 0:\n",
    "        print(i + \": Length = \" + str(total))\n",
    "    x = np.load(get_folder_images_saving_train_x(binary_masks) + \"/\" + str(i) + \".npy\")\n",
    "    y = np.load(get_folder_images_saving_train_y(binary_masks) + \"/\" + str(i) + \".npy\")\n",
    "    crops_x, crops_y = get_all_crops(x, y)\n",
    "    length = crops_x.shape[0]\n",
    "    for j in range(0, length):\n",
    "        # We do not want to keep too many black crops, so we make sure there is some data in both train and label\n",
    "        # matrices before taking the flips.\n",
    "        crop_x_j = crops_x[j]\n",
    "        crop_y_j = crops_y[j]\n",
    "        if np.sum(crop_x_j < lim_min) > min_ones and np.sum(crop_y_j[:, :, 0] < lim_min) > min_ones and \\\n",
    "                        np.sum(crop_y_j[:, :, 1] > lim_min) > min_ones and np.sum(crop_x_j > lim_max) < max_ones and \\\n",
    "                        np.sum(crop_y_j[:, :, 0] > lim_max) < max_ones and np.sum(crop_y_j[:, :, 1] > lim_max) < max_ones:\n",
    "            flips_x, flips_y = get_flips_images(crops_x[j], crops_y[j])\n",
    "            for k in range(0, 4):\n",
    "                total += 1\n",
    "        else:\n",
    "            total += 1\n",
    "            \n",
    "print(\"Length: \" + str(total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
