{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from dataset import *\n",
    "from multi_testing import *\n",
    "from tests import *\n",
    "from image_processing import *\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actin, predicted_dendrite = test_image(397, \"model_yang\", \"dendrites\", binary_masks=False, thresh_results=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Good examples dendrites: 2, 24, 91, 397, 1004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save_train_label_images(1041, binary_masks=False)\n",
    "save_dataset(5, binary_masks=False, channel='axons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## TESTING MODEL model_yang #########\n",
      "######## LOADING THE MODEL ###########\n",
      "number of training examples = 3\n",
      "number of test examples = 2\n",
      "X_train shape: (3, 224, 224, 1)\n",
      "Y_train shape: (3, 224, 224, 1)\n",
      "X_test shape: (2, 224, 224, 1)\n",
      "Y_test shape: (2, 224, 224, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maewanto/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## RUNNING THE MODEL ###########\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m       \u001b[0mxla_compile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaCompile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1704\u001b[0m       raise ValueError(\"No attr named '\" + name + \"' in \" +\n\u001b[0;32m-> 1705\u001b[0;31m                        str(self._node_def))\n\u001b[0m\u001b[1;32m   1706\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No attr named '_XlaCompile' in name: \"bn5/moments/mean\"\nop: \"Mean\"\ninput: \"conv5/BiasAdd\"\ninput: \"bn5/moments/mean/reduction_indices\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_FLOAT\n  }\n}\nattr {\n  key: \"Tidx\"\n  value {\n    type: DT_INT32\n  }\n}\nattr {\n  key: \"keep_dims\"\n  value {\n    b: true\n  }\n}\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0dea392eb056>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     }\n\u001b[1;32m     13\u001b[0m ]\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mrun_multi_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_to_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/ULaval/ApprentissageReconnaissance/Devoirs/GIF-4101_Projet/scripts/multi_testing.py\u001b[0m in \u001b[0;36mrun_multi_tests\u001b[0;34m(models_to_test)\u001b[0m\n\u001b[1;32m     10\u001b[0m             train_model(model['name'], nb_examples=model['nb_examples'], validation_split=model['validation_split'],\n\u001b[1;32m     11\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_saved_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"use_saved_weights\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                         channel=model['channel'], binary_masks=model['binary_masks'], train_test_splitting=model['train_test_splitting'])\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ULaval/ApprentissageReconnaissance/Devoirs/GIF-4101_Projet/scripts/tests.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_name, nb_examples, epochs, batch_size, validation_split, use_saved_weights, evaluate, show_example, channel, binary_masks, train_test_splitting)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m# Run the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"######## RUNNING THE MODEL ###########\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0m_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;31m# Load the best weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ULaval/ApprentissageReconnaissance/Devoirs/GIF-4101_Projet/scripts/tests.py\u001b[0m in \u001b[0;36m_fit_model\u001b[0;34m(my_model, X_train, y_train, validation_split, epochs, batch_size, callbacks)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         return my_model.fit(x=X_train, y=y_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size,\n\u001b[0;32m---> 98\u001b[0;31m                      callbacks=callbacks)\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mResourceExhaustedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"######## ResourceExhaustedError ###########\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1625\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1627\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1628\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    988\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    989\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    991\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m                 \u001b[0;31m# Gets loss and metrics. Updates weights at each call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_updates_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clipnorm'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclipnorm\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   2387\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \"\"\"\n\u001b[0;32m-> 2389\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\u001b[0m\n\u001b[1;32m    540\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m                 in_grads = _MaybeCompile(\n\u001b[0;32m--> 542\u001b[0;31m                     grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    543\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    346\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaScope\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    540\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m                 in_grads = _MaybeCompile(\n\u001b[0;32m--> 542\u001b[0;31m                     grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    543\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MeanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   factor = _safe_shape_div(\n\u001b[0;32m---> 98\u001b[0;31m       math_ops.reduce_prod(input_shape), math_ops.reduce_prod(output_shape))\n\u001b[0m\u001b[1;32m     99\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msum_grad\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_prod\u001b[0;34m(input_tensor, axis, keep_dims, name, reduction_indices)\u001b[0m\n\u001b[1;32m   1417\u001b[0m       \u001b[0m_ReductionDims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m       \u001b[0mkeep_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1419\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_prod\u001b[0;34m(input, reduction_indices, keep_dims, name)\u001b[0m\n\u001b[1;32m   1558\u001b[0m   result = _op_def_lib.apply_op(\"Prod\", input=input,\n\u001b[1;32m   1559\u001b[0m                                 \u001b[0mreduction_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduction_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1560\u001b[0;31m                                 keep_dims=keep_dims, name=name)\n\u001b[0m\u001b[1;32m   1561\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2632\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m   serialized_unknown_shape = (\n\u001b[0;32m--> 641\u001b[0;31m       tensor_shape.TensorShape(None).as_proto().SerializeToString())\n\u001b[0m\u001b[1;32m    642\u001b[0m   \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mserialized_unknown_shape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models_to_test = [\n",
    "    {\n",
    "        'name': 'model_yang',\n",
    "        'nb_examples': 5,\n",
    "        'validation_split': 0.3,\n",
    "        'epochs': 1,\n",
    "        'batch_size': 4,\n",
    "        'use_saved_weights': False,\n",
    "        'channel': 'axons',\n",
    "        'binary_masks': False,\n",
    "        'train_test_splitting': True\n",
    "    }\n",
    "]\n",
    "run_multi_tests(models_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_files_path_generator():\n",
    "    \"\"\"\n",
    "    Generator of original tif files' path\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for subdir, dirs, files in os.walk(original_data):\n",
    "        for file in files:\n",
    "            filename, file_extension = os.path.splitext(file)\n",
    "            if file_extension == \".tif\":\n",
    "                yield os.path.join(subdir, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = 1041\n",
    "count = 0\n",
    "min_rows = np.inf\n",
    "min_cols = np.inf\n",
    "min_rows_img = \"\"\n",
    "min_cols_img = \"\"\n",
    "i = 0\n",
    "for file_path in get_files_path_generator():\n",
    "    if i % 10 == 0:\n",
    "        print(str(i + 1) + \"/\" + str(N))\n",
    "    image = tifffile.imread(file_path)\n",
    "    # Remove number of channels from shape\n",
    "    shape = image.shape[1:]\n",
    "    if min_rows > shape[0]:\n",
    "        min_rows = shape[0]\n",
    "        min_rows_img = file_path\n",
    "    if min_cols > shape[1]:\n",
    "        min_cols = shape[1]\n",
    "        min_cols_img = file_path\n",
    "#     if shape[0] < 448 or shape[1] < 448:\n",
    "#         count += 1\n",
    "#         print(file_path)\n",
    "#         os.rename(file_path, file_path.replace(\"original_data\", \"too_small_images\"))\n",
    "    i += 1\n",
    "# print(count)\n",
    "print(min_rows)\n",
    "print(min_rows_img)\n",
    "print(min_cols)\n",
    "print(min_cols_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_images = 2\n",
    "binary_masks = False\n",
    "min_ones_ratio=0.2\n",
    "max_ones_ratio=0.8\n",
    "lim_min=0.1\n",
    "lim_max=0.9\n",
    "\n",
    "print(\"AUGMENTING THE DATA\")\n",
    "min_ones = crop_size * crop_size * min_ones_ratio\n",
    "max_ones = crop_size * crop_size * max_ones_ratio\n",
    "train_set_x_axon_orig = []\n",
    "train_set_y_axon_orig = []\n",
    "train_set_x_dendrite_orig = []\n",
    "train_set_y_dendrite_orig = []\n",
    "for i in range(0, nb_images):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    x = np.load(get_folder_images_saving_train_x(binary_masks) + \"/\" + str(i) + \".npy\")\n",
    "    y = np.load(get_folder_images_saving_train_y(binary_masks) + \"/\" + str(i) + \".npy\")\n",
    "    crops_x, crops_y = get_all_crops(x, y)\n",
    "    length = crops_x.shape[0]\n",
    "    for j in range(0, length):\n",
    "        # The discriminant crops will be the ones where there is some difference between the actin and the\n",
    "        # axons/dendrites. Only these ones will be flipped.\n",
    "        crop_x_j = crops_x[j]\n",
    "        crop_y_j = crops_y[j]\n",
    "\n",
    "        positive_axon = np.where(crop_y_j[:, :, 0] > 0)\n",
    "        actin_minus_axon = crop_x_j.copy()\n",
    "        actin_minus_axon[positive_axon] = 0\n",
    "        if np.sum(actin_minus_axon > 0) > min_ones:\n",
    "            flips_x, flips_y = get_flips_images(crops_x[j], crops_y[j])\n",
    "            for k in range(0, 4):\n",
    "                train_set_x_axon_orig.append(flips_x[k])\n",
    "                train_set_y_axon_orig.append(flips_y[k, :, :, 0])\n",
    "        else:\n",
    "            train_set_x_axon_orig.append(crops_x[j])\n",
    "            train_set_y_axon_orig.append(crops_y[j, :, :, 0])\n",
    "\n",
    "        positive_dendrite = np.where(crop_y_j[:, :, 1] > 0)\n",
    "        actin_minus_dendrite = crop_x_j.copy()\n",
    "        actin_minus_dendrite[positive_dendrite] = 0\n",
    "        if np.sum(actin_minus_dendrite > 0) > min_ones:\n",
    "            flips_x, flips_y = get_flips_images(crops_x[j], crops_y[j])\n",
    "            for k in range(0, 4):\n",
    "                train_set_x_dendrite_orig.append(flips_x[k])\n",
    "                train_set_y_dendrite_orig.append(flips_y[k, :, :, 1])\n",
    "        else:\n",
    "            train_set_x_dendrite_orig.append(crops_x[j])\n",
    "            train_set_y_dendrite_orig.append(crops_y[j, :, :, 1])\n",
    "            \n",
    "# Save the created data sets to an hdf5 file.\n",
    "print(\"SAVING THE HDF5 FILE\")\n",
    "with h5py.File(get_dataset_h5py_path(binary_masks), 'w') as f:\n",
    "    length_axons = len(train_set_x_axon_orig)\n",
    "    print(\"Length axons: \" + str(length_axons))\n",
    "    dataset = f.create_dataset(\"X_axon\", (length_axons, crop_size, crop_size, 1))\n",
    "    dataset[...] = np.array(train_set_x_axon_orig)\n",
    "    dataset = f.create_dataset(\"y_axon\", (length_axons, crop_size, crop_size, 1))\n",
    "    dataset[...] = np.expand_dims(np.array(train_set_y_axon_orig), axis=3)\n",
    "\n",
    "    length_dendrites = len(train_set_x_dendrite_orig)\n",
    "    print(\"Length dendrites: \" + str(length_dendrites))\n",
    "    dataset = f.create_dataset(\"X_dendrite\", (length_dendrites, crop_size, crop_size, 1))\n",
    "    dataset[...] = np.array(train_set_x_dendrite_orig)\n",
    "    dataset = f.create_dataset(\"y_dendrite\", (length_dendrites, crop_size, crop_size, 1))\n",
    "    dataset[...] = np.expand_dims(np.array(train_set_y_dendrite_orig), axis=3)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(get_test_data_folder_after_training('model_yang', 'axons', False) + '/x.npy')\n",
    "y_test = np.load(get_test_data_folder_after_training('model_yang', 'axons', False) + '/y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+FQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f68f3fc4518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "actin, axon = get_images_from_train_label(X_test[i], y_test[i], 'axons')\n",
    "plt.imshow(axon)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
